{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke_Prediction_18: PODSTAWOWY MODEL KLASYFIKACJI PYTORCH PRZEZ OSADZANIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 24 15:52:51 2020\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time() ## pomiar czasu: start pomiaru czasu\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odpalam karte graficzną GPU (której nie mam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu') # obliczenia robie na CPU\n",
    "#device = torch.device('cuda') # obliczenia robie na GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importuję dane "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Heart_Disease</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Type_Of_Work</th>\n",
       "      <th>Residence</th>\n",
       "      <th>Avg_Glucose</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking_Status</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Age_years</th>\n",
       "      <th>Age_years_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30650</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>58.093151</td>\n",
       "      <td>(53.126, 59.076]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>57008</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>70.076712</td>\n",
       "      <td>(65.121, 74.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>53725</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>77.59</td>\n",
       "      <td>17.7</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>52.041096</td>\n",
       "      <td>(48.082, 53.126]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     ID  Gender  Hypertension  Heart_Disease Ever_Married  \\\n",
       "0           1  30650    Male             1              0          Yes   \n",
       "1           3  57008  Female             0              0          Yes   \n",
       "2           6  53725  Female             0              0          Yes   \n",
       "\n",
       "  Type_Of_Work Residence  Avg_Glucose   BMI   Smoking_Status  Stroke  \\\n",
       "0      Private     Urban        87.96  39.2     never smoked       0   \n",
       "1      Private     Rural        69.04  35.9  formerly smoked       0   \n",
       "2      Private     Urban        77.59  17.7  formerly smoked       0   \n",
       "\n",
       "   Age_years      Age_years_10  \n",
       "0  58.093151  (53.126, 59.076]  \n",
       "1  70.076712   (65.121, 74.11]  \n",
       "2  52.041096  (48.082, 53.126]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/wojciech/Pulpit/1/Stroke_Prediction_CLEAR.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29062, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f171a319350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Stroke.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=['#45818e', '#f1c232'], explode=(0.05, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uporządkowanie kolumn z danymi kategorycznymi i danymi ciągłymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID', 'Gender', 'Hypertension', 'Heart_Disease',\n",
       "       'Ever_Married', 'Type_Of_Work', 'Residence', 'Avg_Glucose', 'BMI',\n",
       "       'Smoking_Status', 'Stroke', 'Age_years', 'Age_years_10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Private\n",
       "1              Private\n",
       "2              Private\n",
       "3        Self-employed\n",
       "4              Private\n",
       "             ...      \n",
       "29057         children\n",
       "29058         Govt_job\n",
       "29059          Private\n",
       "29060          Private\n",
       "29061          Private\n",
       "Name: Type_Of_Work, Length: 29062, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type_Of_Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Gender','Hypertension', 'Heart_Disease','Ever_Married','Type_Of_Work','Residence','Smoking_Status','Age_years_10']\n",
    "numerical_columns = ['Avg_Glucose', 'BMI', 'Age_years']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ustalamy, że zmienną wynikową jest kolumna 'Stroke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ['Stroke']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyfryzacja zmiennych tekstowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          int64\n",
       "ID                  int64\n",
       "Gender             object\n",
       "Hypertension        int64\n",
       "Heart_Disease       int64\n",
       "Ever_Married       object\n",
       "Type_Of_Work       object\n",
       "Residence          object\n",
       "Avg_Glucose       float64\n",
       "BMI               float64\n",
       "Smoking_Status     object\n",
       "Stroke              int64\n",
       "Age_years         float64\n",
       "Age_years_10       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musimy przekonwertować typy dla kolumn jakościowych na category. Możemy to zrobić za pomocą astype() funkcji, jak pokazano poniżej:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Wprowadzam nowy typ danych: 'category'</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categorical_columns:\n",
    "    df[category] = df[category].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           int64\n",
       "ID                   int64\n",
       "Gender            category\n",
       "Hypertension      category\n",
       "Heart_Disease     category\n",
       "Ever_Married      category\n",
       "Type_Of_Work      category\n",
       "Residence         category\n",
       "Avg_Glucose        float64\n",
       "BMI                float64\n",
       "Smoking_Status    category\n",
       "Stroke               int64\n",
       "Age_years          float64\n",
       "Age_years_10      category\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rural', 'Urban'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Residence'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['No', 'Yes'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ever_Married'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(22.041, 29.055]', '(29.055, 36.058]', '(36.058, 42.132]',\n",
       "       '(42.132, 48.082]', '(48.082, 53.126]', '(53.126, 59.076]',\n",
       "       '(59.076, 65.121]', '(65.121, 74.11]', '(74.11, 82.137]',\n",
       "       '(9.999, 22.041]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age_years_10'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyfryzacja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           int64\n",
       "ID                   int64\n",
       "Gender            category\n",
       "Hypertension      category\n",
       "Heart_Disease     category\n",
       "Ever_Married      category\n",
       "Type_Of_Work      category\n",
       "Residence         category\n",
       "Avg_Glucose        float64\n",
       "BMI                float64\n",
       "Smoking_Status    category\n",
       "Stroke               int64\n",
       "Age_years          float64\n",
       "Age_years_10      category\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dlaczego zcyfrowaliśmy dane w formacie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podstawowym celem oddzielenia kolumn kategorycznych od kolumn numerycznych jest to, że wartości w kolumnie numerycznej mogą być bezpośrednio wprowadzane do sieci neuronowych. Jednak wartości kolumn kategorialnych należy najpierw przekonwertować na typy liczbowe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Hypertension',\n",
       " 'Heart_Disease',\n",
       " 'Ever_Married',\n",
       " 'Type_Of_Work',\n",
       " 'Residence',\n",
       " 'Smoking_Status',\n",
       " 'Age_years_10']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konwersja zmiennych kategorycznych na macierz Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 2, 1, 1, 5],\n",
       "       [0, 0, 0, 1, 2, 0, 0, 7],\n",
       "       [0, 0, 0, 1, 2, 1, 0, 4],\n",
       "       [0, 0, 1, 1, 3, 0, 1, 8],\n",
       "       [0, 0, 0, 1, 2, 0, 2, 1],\n",
       "       [0, 1, 0, 1, 3, 1, 1, 7],\n",
       "       [1, 0, 1, 1, 2, 1, 0, 8],\n",
       "       [0, 0, 0, 1, 2, 0, 1, 2],\n",
       "       [0, 0, 0, 1, 2, 0, 0, 2],\n",
       "       [0, 0, 0, 1, 2, 0, 1, 2]], dtype=int8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = df['Gender'].cat.codes.values\n",
    "p2 = df['Hypertension'].cat.codes.values\n",
    "p3 = df['Heart_Disease'].cat.codes.values\n",
    "p4 = df['Ever_Married'].cat.codes.values\n",
    "p5 = df['Type_Of_Work'].cat.codes.values\n",
    "p6 = df['Residence'].cat.codes.values\n",
    "p7 = df['Smoking_Status'].cat.codes.values\n",
    "p8 = df['Age_years_10'].cat.codes.values\n",
    "\n",
    "NumP_matrix = np.stack([p1, p2, p3, p4, p5, p6, p7, p8], 1)\n",
    "\n",
    "NumP_matrix[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie tensora Pytorch z macierzy Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 0, 1, 2, 1, 1, 5],\n",
       "        [0, 0, 0, 1, 2, 0, 0, 7],\n",
       "        [0, 0, 0, 1, 2, 1, 0, 4],\n",
       "        [0, 0, 1, 1, 3, 0, 1, 8],\n",
       "        [0, 0, 0, 1, 2, 0, 2, 1],\n",
       "        [0, 1, 0, 1, 3, 1, 1, 7],\n",
       "        [1, 0, 1, 1, 2, 1, 0, 8],\n",
       "        [0, 0, 0, 1, 2, 0, 1, 2],\n",
       "        [0, 0, 0, 1, 2, 0, 0, 2],\n",
       "        [0, 0, 0, 1, 2, 0, 1, 2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data = torch.tensor(NumP_matrix, dtype=torch.int64)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konwersja kolumn numerycznych DataFrame na tensor Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 87.9600,  39.2000,  58.0932],\n",
       "        [ 69.0400,  35.9000,  70.0767],\n",
       "        [ 77.5900,  17.7000,  52.0411],\n",
       "        [243.5300,  27.0000,  75.1041],\n",
       "        [ 77.6700,  32.3000,  32.0247]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data = np.stack([df[col].values for col in numerical_columns], 1)\n",
    "numerical_data = torch.tensor(numerical_data, dtype=torch.float)\n",
    "numerical_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konwersja zmiennych wynikowych na tensor Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = torch.tensor(df[outputs].values).flatten()\n",
    "outputs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podsumujmy tensory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_data:  torch.Size([29062, 8])\n",
      "numerical_data:    torch.Size([29062, 3])\n",
      "outputs:           torch.Size([29062])\n"
     ]
    }
   ],
   "source": [
    "print('categorical_data: ',categorical_data.shape)\n",
    "print('numerical_data:   ',numerical_data.shape)\n",
    "print('outputs:          ',outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">OSADZANIE</span>\n",
    "Przekształciliśmy nasze kolumny kategorialne na numeryczne, w których unikatowa wartość jest reprezentowana przez jedną liczbę całkowitą (cyfryzacja - np. palący to 1). Na podstawie takiej kolumny (zmiennej) możemy wyszkolić model, jednak jest lepszy sposób...\n",
    "\n",
    "Lepszym sposobem jest reprezentowanie wartości w kolumnie kategorialnej w postaci wektora N-wymiarowego zamiast pojedynczej liczby całkowitej. Ten proces nazywa się osadzaniem. Wektor jest w stanie przechwycić więcej informacji i może znaleźć związki między różnymi wartościami kategorycznymi w bardziej odpowiedni sposób. Dlatego będziemy reprezentować wartości w kolumnach kategorialnych w postaci wektorów N-wymiarowych. \n",
    "\n",
    "Musimy zdefiniować rozmiar osadzania (wymiary wektorowe) dla wszystkich kolumn jakościowych. Nie ma twardej i szybkiej reguły dotyczącej liczby wymiarów. Dobrą zasadą przy definiowaniu rozmiaru osadzania dla kolumny jest podzielenie liczby unikalnych wartości w kolumnie przez 2 (ale nie więcej niż 50). Na przykład dla 'Smoking_Status' kolumny liczba unikalnych wartości wynosi 3. Odpowiedni rozmiar osadzenia dla kolumny 'Smoking_Status'będzie wynosił 3/2 = 1,5 = 2 (zaokrąglenie).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy skrypt tworzy krotkę zawierającą liczbę unikalnych wartości i rozmiarów wymiarów dla wszystkich kolumn jakościowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zasada jest prosta: macierz embadding musi być zawsze w ilości wierszy większa niż zakres zmiennych w ilości wierszy: dlatego dodałem col_size+2, to duży zapas.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 3), (4, 3), (4, 3), (4, 3), (7, 5), (4, 3), (5, 4), (12, 7)]\n"
     ]
    }
   ],
   "source": [
    "categorical_column_sizes = [len(df[column].cat.categories) for column in categorical_columns]\n",
    "categorical_embedding_sizes = [(col_size+2, min(50, (col_size+5)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dzielenie zestawu na szkoleniowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_records = df['ID'].count()\n",
    "test_records = int(total_records * .2)\n",
    "\n",
    "categorical_train_data = categorical_data[:total_records-test_records]\n",
    "categorical_test_data = categorical_data[total_records-test_records:total_records]\n",
    "numerical_train_data = numerical_data[:total_records-test_records]\n",
    "numerical_test_data = numerical_data[total_records-test_records:total_records]\n",
    "train_outputs = outputs[:total_records-test_records]\n",
    "test_outputs = outputs[total_records-test_records:total_records]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby sprawdzić, czy poprawnie podzieliliśmy dane na zestawy treningów i testów, wydrukujmy długości rekordów szkolenia i testów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_train_data:  torch.Size([23250, 8])\n",
      "numerical_train_data:    torch.Size([23250, 3])\n",
      "train_outputs:           torch.Size([23250])\n",
      "----------------------------------------------------\n",
      "categorical_test_data:   torch.Size([5812, 8])\n",
      "numerical_test_data:     torch.Size([5812, 3])\n",
      "test_outputs:            torch.Size([5812])\n"
     ]
    }
   ],
   "source": [
    "print('categorical_train_data: ',categorical_train_data.shape)\n",
    "print('numerical_train_data:   ',numerical_train_data.shape)\n",
    "print('train_outputs:          ', train_outputs.shape)\n",
    "print('----------------------------------------------------')\n",
    "print('categorical_test_data:  ',categorical_test_data.shape)\n",
    "print('numerical_test_data:    ',numerical_test_data.shape)\n",
    "print('test_outputs:           ',test_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie modelu klasyfikacji Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, num_numerical_cols, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "        self.batch_norm_num = nn.BatchNorm1d(num_numerical_cols)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols + num_numerical_cols\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_categorical, x_numerical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "\n",
    "        x_numerical = self.batch_norm_num(x_numerical)\n",
    "        x = torch.cat([x, x_numerical], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_embedding_sizes:   [(4, 3), (4, 3), (4, 3), (4, 3), (7, 5), (4, 3), (5, 4), (12, 7)]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print('categorical_embedding_sizes:  ',categorical_embedding_sizes)\n",
    "print(numerical_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(categorical_embedding_sizes, numerical_data.shape[1], 2, [200,100,50], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(4, 3)\n",
      "    (1): Embedding(4, 3)\n",
      "    (2): Embedding(4, 3)\n",
      "    (3): Embedding(4, 3)\n",
      "    (4): Embedding(7, 5)\n",
      "    (5): Embedding(4, 3)\n",
      "    (6): Embedding(5, 4)\n",
      "    (7): Embedding(12, 7)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (batch_norm_num): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=34, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie dunkcji straty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "#loss_function = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiowanie optymalizatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.Rprop(model.parameters(), lr=0.001, etas=(0.5, 1.2), step_sizes=(1e-06, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_embedding_sizes:   [(4, 3), (4, 3), (4, 3), (4, 3), (7, 5), (4, 3), (5, 4), (12, 7)]\n",
      "3\n",
      "categorical_train_data:  torch.Size([23250, 8])\n",
      "numerical_train_data:    torch.Size([23250, 3])\n",
      "outputs:                 torch.Size([23250])\n"
     ]
    }
   ],
   "source": [
    "print('categorical_embedding_sizes:  ',categorical_embedding_sizes)\n",
    "print(numerical_data.shape[1])\n",
    "print('categorical_train_data: ',categorical_train_data.shape)\n",
    "print('numerical_train_data:   ',numerical_train_data.shape)\n",
    "print('outputs:                ',train_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(categorical_train_data, numerical_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.88311106\n",
      "epoch:  31 loss: 0.73839533\n",
      "epoch:  61 loss: 0.63669974\n",
      "epoch:  91 loss: 0.46215561\n",
      "epoch: 121 loss: 0.27455056\n",
      "epoch: 151 loss: 0.15695815\n",
      "epoch: 181 loss: 0.10792922\n",
      "epoch: 211 loss: 0.09656636\n",
      "epoch: 241 loss: 0.09418554\n",
      "epoch: 271 loss: 0.08802118\n",
      "epoch: 300 loss: 0.0843942240\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "aggregated_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(categorical_train_data, numerical_train_data)\n",
    "    \n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i%30 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), aggregated_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackabuse.com/introduction-to-pytorch-for-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prognoza na podstawie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train_set: 0.08522564\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_val_train = model(categorical_train_data, numerical_train_data)\n",
    "    loss = loss_function( y_val_train, train_outputs)\n",
    "print(f'Loss train_set: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09486609\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_val = model(categorical_test_data, numerical_test_data)\n",
    "    loss = loss_function(y_val, test_outputs)\n",
    "print(f'Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ ustaliliśmy, że nasza warstwa wyjściowa będzie zawierać 2 neurony, każda prognoza będzie zawierać 2 wartości. Przykładowo pierwsze 5 przewidywanych wartości wygląda następująco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7729, -2.1325],\n",
      "        [ 2.8719, -2.2358],\n",
      "        [ 0.7363, -1.1285],\n",
      "        [ 2.4189, -2.3633],\n",
      "        [ 1.9768, -1.9941]])\n"
     ]
    }
   ],
   "source": [
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celem takich prognoz jest to, że jeśli rzeczywisty wynik wynosi 0, wartość przy indeksie 0 powinna być wyższa niż wartość przy indeksie 1 i odwrotnie. Możemy pobrać indeks największej wartości z listy za pomocą następującego skryptu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyższe równanie zwraca wskaźniki wartości maksymalnych wzdłuż osi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(y_val[:195])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ na liście pierwotnie przewidywanych wyników dla pierwszych pięciu rekordów wartości przy zerowych indeksach są większe niż wartości przy pierwszych indeksach, możemy zobaczyć 0 w pierwszych pięciu wierszach przetworzonych danych wyjściowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5689    0]\n",
      " [ 123    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5689\n",
      "           1       0.00      0.00      0.00       123\n",
      "\n",
      "    accuracy                           0.98      5812\n",
      "   macro avg       0.49      0.50      0.49      5812\n",
      "weighted avg       0.96      0.98      0.97      5812\n",
      "\n",
      "0.9788368891947694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wojciech/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(test_outputs,y_val))\n",
    "print(classification_report(test_outputs,y_val))\n",
    "print(accuracy_score(test_outputs, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model słabo wykrywa udar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zapisujemy cały model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wojciech/anaconda3/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model,'/home/wojciech/Pulpit/3/byk.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odtwarzamy cały model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (all_embeddings): ModuleList(\n",
       "    (0): Embedding(4, 3)\n",
       "    (1): Embedding(4, 3)\n",
       "    (2): Embedding(4, 3)\n",
       "    (3): Embedding(4, 3)\n",
       "    (4): Embedding(7, 5)\n",
       "    (5): Embedding(4, 3)\n",
       "    (6): Embedding(5, 4)\n",
       "    (7): Embedding(12, 7)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
       "  (batch_norm_num): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=34, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.4, inplace=False)\n",
       "    (12): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KOT = torch.load('/home/wojciech/Pulpit/3/byk.pb')\n",
    "KOT.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podstawiając inne zmienne niezależne można uzyskać wektor zmiennych wyjściowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 0,  ..., 1, 1, 5],\n",
       "        [0, 1, 0,  ..., 0, 1, 5],\n",
       "        [1, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 9],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [1, 0, 0,  ..., 1, 1, 9]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = categorical_train_data[::50]\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 87.9600,  39.2000,  58.0932],\n",
       "        [235.8500,  40.1000,  57.0329],\n",
       "        [ 80.8100,  33.2000,  34.1260],\n",
       "        ...,\n",
       "        [139.9900,  26.8000,  20.0493],\n",
       "        [ 61.3100,  33.1000,  29.0575],\n",
       "        [ 92.2200,  35.0000,  21.0603]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = numerical_train_data[::50]\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =train_outputs[::50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8608, -1.9731],\n",
       "        [ 1.5545, -1.8781],\n",
       "        [ 2.3705, -2.1801],\n",
       "        [ 1.4825, -1.7660],\n",
       "        [ 1.9961, -2.0050],\n",
       "        [ 2.0910, -2.0830],\n",
       "        [ 2.2859, -2.1231],\n",
       "        [ 1.9538, -2.0031],\n",
       "        [ 2.2112, -2.1295],\n",
       "        [ 2.4439, -2.1890]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_AB = KOT(A, B)\n",
    "y_pred_AB[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train_set: 0.10529844\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_val_AB = KOT(A,B)\n",
    "    loss = loss_function( y_val_AB, y)\n",
    "print(f'Loss train_set: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.argmax(y_val_AB, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[453   0]\n",
      " [ 12   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       453\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.97       465\n",
      "   macro avg       0.49      0.50      0.49       465\n",
      "weighted avg       0.95      0.97      0.96       465\n",
      "\n",
      "0.9741935483870968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y,y_val))\n",
    "print(classification_report(y,y_val))\n",
    "print(accuracy_score(y, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pomiar czasu wykonania tego zadania:\n",
      "347.3095963001251\n"
     ]
    }
   ],
   "source": [
    "print('Pomiar czasu wykonania tego zadania:')\n",
    "print(time.time() - start_time) ## koniec pomiaru czasu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU: 352 s\n",
    "CPU: 347 s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
